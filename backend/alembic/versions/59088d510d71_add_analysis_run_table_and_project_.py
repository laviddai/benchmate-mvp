"""Add analysis_run table and project relationship

Revision ID: 59088d510d71
Revises: 7a4e59542899
Create Date: 2025-05-23 12:10:12.713164

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '59088d510d71'
down_revision: Union[str, None] = '7a4e59542899'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('analysis_runs',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=True),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('tool_id', sa.String(length=255), nullable=False),
    sa.Column('tool_version', sa.String(length=50), nullable=True),
    sa.Column('parameters', sa.JSON(), nullable=True),
    sa.Column('status', sa.Enum('PENDING', 'RUNNING', 'COMPLETED', 'FAILED', 'CANCELLED', name='analysis_status_enum'), nullable=False),
    sa.Column('primary_input_dataset_id', sa.UUID(), nullable=True),
    sa.Column('output_artifacts', sa.JSON(), nullable=True),
    sa.Column('run_log', sa.Text(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('queued_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('started_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('completed_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('project_id', sa.UUID(), nullable=False),
    sa.Column('created_by_user_id', sa.UUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['created_by_user_id'], ['users.id'], name=op.f('fk_analysis_runs_created_by_user_id_users')),
    sa.ForeignKeyConstraint(['primary_input_dataset_id'], ['datasets.id'], name=op.f('fk_analysis_runs_primary_input_dataset_id_datasets')),
    sa.ForeignKeyConstraint(['project_id'], ['projects.id'], name=op.f('fk_analysis_runs_project_id_projects')),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_analysis_runs'))
    )
    with op.batch_alter_table('analysis_runs', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_analysis_runs_created_by_user_id'), ['created_by_user_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_analysis_runs_id'), ['id'], unique=False)
        batch_op.create_index(batch_op.f('ix_analysis_runs_name'), ['name'], unique=False)
        batch_op.create_index(batch_op.f('ix_analysis_runs_primary_input_dataset_id'), ['primary_input_dataset_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_analysis_runs_project_id'), ['project_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_analysis_runs_status'), ['status'], unique=False)
        batch_op.create_index(batch_op.f('ix_analysis_runs_tool_id'), ['tool_id'], unique=False)

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('analysis_runs', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_analysis_runs_tool_id'))
        batch_op.drop_index(batch_op.f('ix_analysis_runs_status'))
        batch_op.drop_index(batch_op.f('ix_analysis_runs_project_id'))
        batch_op.drop_index(batch_op.f('ix_analysis_runs_primary_input_dataset_id'))
        batch_op.drop_index(batch_op.f('ix_analysis_runs_name'))
        batch_op.drop_index(batch_op.f('ix_analysis_runs_id'))
        batch_op.drop_index(batch_op.f('ix_analysis_runs_created_by_user_id'))

    op.drop_table('analysis_runs')
    # ### end Alembic commands ###
